{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ideal-beaver"
   },
   "source": [
    "# SlowFast\n",
    "\n",
    "*Author: FAIR PyTorchVideo*\n",
    "\n",
    "**SlowFast networks pretrained on the Kinetics 400 dataset**\n",
    "\n",
    "\n",
    "### Example Usage\n",
    "\n",
    "#### Imports\n",
    "\n",
    "Load the model:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "oriented-istanbul",
    "outputId": "6cc17f7e-7304-48fa-e259-e95050cbbe93"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jlee0/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "# Choose the `slowfast_r50` model \n",
    "model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "dutch-oliver"
   },
   "source": [
    "Import remaining functions:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "academic-shipping",
    "outputId": "64e0ea38-82f4-4724-fa9e-caa62b3c565b"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlee0\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\_functional_video.py:7: UserWarning: The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms.functional' module instead.\n",
      "  \"The 'torchvision.transforms._functional_video' module is deprecated since 0.12 and will be removed in 0.14. \"\n",
      "C:\\Users\\jlee0\\anaconda3\\lib\\site-packages\\torchvision\\transforms\\_transforms_video.py:26: UserWarning: The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in 0.14. Please use the 'torchvision.transforms' module instead.\n",
      "  \"The 'torchvision.transforms._transforms_video' module is deprecated since 0.12 and will be removed in 0.14. \"\n"
     ]
    }
   ],
   "source": [
    "from typing import Dict\n",
    "import json\n",
    "import urllib\n",
    "from torchvision.transforms import Compose, Lambda\n",
    "from torchvision.transforms._transforms_video import (\n",
    "    CenterCropVideo,\n",
    "    NormalizeVideo,\n",
    ")\n",
    "from pytorchvideo.data.encoded_video import EncodedVideo\n",
    "from pytorchvideo.transforms import (\n",
    "    ApplyTransformToKey,\n",
    "    ShortSideScale,\n",
    "    UniformTemporalSubsample,\n",
    "    UniformCropVideo\n",
    ") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "remarkable-pittsburgh"
   },
   "source": [
    "#### Setup\n",
    "\n",
    "Set the model to eval mode and move to desired device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "attributes": {
     "classes": [
      "python "
     ],
     "id": ""
    },
    "id": "mobile-marble"
   },
   "outputs": [],
   "source": [
    "# Set to GPU or CPU\n",
    "device = \"cpu\"\n",
    "model = model.eval()\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "handmade-nylon"
   },
   "source": [
    "Download the id to label mapping for the Kinetics 400 dataset on which the torch hub models were trained. This will be used to get the category label names from the predicted class ids."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "southern-plate"
   },
   "outputs": [],
   "source": [
    "json_url = \"https://dl.fbaipublicfiles.com/pyslowfast/dataset/class_names/kinetics_classnames.json\"\n",
    "json_filename = \"kinetics_classnames.json\"\n",
    "try: urllib.URLopener().retrieve(json_url, json_filename)\n",
    "except: urllib.request.urlretrieve(json_url, json_filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "another-newark"
   },
   "outputs": [],
   "source": [
    "with open(json_filename, \"r\") as f:\n",
    "    kinetics_classnames = json.load(f)\n",
    "\n",
    "# Create an id to label name mapping\n",
    "kinetics_id_to_classname = {}\n",
    "for k, v in kinetics_classnames.items():\n",
    "    kinetics_id_to_classname[v] = str(k).replace('\"', \"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "likely-earth"
   },
   "source": [
    "#### Define input transform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "id": "personalized-growing"
   },
   "outputs": [],
   "source": [
    "side_size = 256 #원하는 video size\n",
    "mean = [0.45, 0.45, 0.45] #정규화를 위한 mean 정의\n",
    "std = [0.225, 0.225, 0.225] #정규화를 위한 std 정의\n",
    "crop_size = 256 #원하는 video size\n",
    "num_frames = 32 #샘플링을 위한 frames 정의\n",
    "sampling_rate = 2 #input clip의 길이를 정의하기 위해 사용\n",
    "frames_per_second = 30 #영상의 기본 fps\n",
    "slowfast_alpha = 4 #slow path와 fast path의 frames 비율을 정해주기 위해 사용\n",
    "num_clips = 10\n",
    "num_crops = 3\n",
    "\n",
    "class PackPathway(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Transform for converting video frames as a list of tensors. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, frames: torch.Tensor):\n",
    "        fast_pathway = frames\n",
    "        # Perform temporal sampling from the fast pathway.\n",
    "        slow_pathway = torch.index_select(\n",
    "            frames,\n",
    "            1,\n",
    "            torch.linspace(\n",
    "                0, frames.shape[1] - 1, frames.shape[1] // slowfast_alpha\n",
    "            ).long(),\n",
    "        )\n",
    "        frame_list = [slow_pathway, fast_pathway]\n",
    "        return frame_list\n",
    "\n",
    "transform =  ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            Lambda(lambda x: x/255.0),\n",
    "            NormalizeVideo(mean, std), #비디오 정규화, 각 채널(=3)에 대해 적용된다\n",
    "            ShortSideScale(\n",
    "                size=side_size\n",
    "            ),\n",
    "            CenterCropVideo(crop_size),\n",
    "            PackPathway()\n",
    "        ]\n",
    "    ),\n",
    ")\n",
    "\n",
    "# The duration of the input clip is also specific to the model.\n",
    "clip_duration = (num_frames * sampling_rate)/frames_per_second #전체 video를 몇 초 clip으로 나눌지 선정"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "emerging-paraguay"
   },
   "source": [
    "#### Run Inference\n",
    "\n",
    "Download an example video."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "id": "restricted-chorus"
   },
   "outputs": [],
   "source": [
    "url_link = \"https://dl.fbaipublicfiles.com/pytorchvideo/projects/archery.mp4\"\n",
    "video_path = 'archery.mp4'\n",
    "try: urllib.URLopener().retrieve(url_link, video_path)\n",
    "except: urllib.request.urlretrieve(url_link, video_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "offshore-newsletter"
   },
   "source": [
    "Load the video and transform it to the input format required by the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "id": "valuable-rating"
   },
   "outputs": [],
   "source": [
    "# Select the duration of the clip to load by specifying the start and end duration\n",
    "# The start_sec should correspond to where the action occurs in the video\n",
    "start_sec = 0\n",
    "end_sec = start_sec + clip_duration\n",
    "\n",
    "# Initialize an EncodedVideo helper class and load the video\n",
    "video = EncodedVideo.from_path(video_path)\n",
    "\n",
    "# Load the desired clip\n",
    "video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
    "\n",
    "# Apply a transform to normalize the video input\n",
    "video_data = transform(video_data)\n",
    "\n",
    "# Move the inputs to the desired device\n",
    "inputs = video_data[\"video\"]\n",
    "inputs = [i.to(device)[None, ...] for i in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow pathway : torch.Size([1, 3, 8, 256, 256])\n",
      "fast pathway : torch.Size([1, 3, 32, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print('slow pathway :',inputs[0].shape)\n",
    "print('fast pathway :',inputs[1].shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "split-graham"
   },
   "source": [
    "#### Get Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "three-consent",
    "outputId": "b62970dd-3d07-4e0d-da5b-f815ee4094a7"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted labels: archery, throwing axe, playing paintball, disc golfing, riding or walking with horse\n"
     ]
    }
   ],
   "source": [
    "# Pass the input clip through the model\n",
    "preds = model(inputs)\n",
    "\n",
    "# Get the predicted classes\n",
    "post_act = torch.nn.Softmax(dim=1)\n",
    "preds = post_act(preds)\n",
    "pred_classes = preds.topk(k=5).indices[0]\n",
    "\n",
    "# Map the predicted classes to the label names\n",
    "pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes]\n",
    "print(\"Top 5 predicted labels: %s\" % \", \".join(pred_class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "insured-elder"
   },
   "source": [
    "### Model Description\n",
    "SlowFast model architectures are based on [1] with pretrained weights using the 8x8 setting\n",
    "on the Kinetics dataset. \n",
    "\n",
    "| arch | depth | frame length x sample rate | top 1 | top 5 | Flops (G) | Params (M) |\n",
    "| --------------- | ----------- | ----------- | ----------- | ----------- | ----------- |  ----------- | ----------- |\n",
    "| SlowFast | R50   | 8x8                        | 76.94 | 92.69 | 65.71     | 34.57      |\n",
    "| SlowFast | R101  | 8x8                        | 77.90 | 93.27 | 127.20    | 62.83      |\n",
    "\n",
    "\n",
    "### References\n",
    "[1] Christoph Feichtenhofer et al, \"SlowFast Networks for Video Recognition\"\n",
    "https://arxiv.org/pdf/1812.03982.pdf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FCjbVULxpNKi"
   },
   "source": [
    "### Predict for overlapping clips (archery)\n",
    "\n",
    "하나의 영상에 대해 frames를 overlapping해 분류 작업을 수행하였다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "id": "HbxEoA3cpMFx"
   },
   "outputs": [],
   "source": [
    "num_frames = 30\n",
    "sampling_rate = 2 \n",
    "frames_per_second = 30\n",
    "\n",
    "clip_duration = (num_frames * sampling_rate)/frames_per_second"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TEw6M9_PqCnC",
    "outputId": "f69c4124-c48f-479a-c7e6-abe7e62d1991"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1 sec Top 1 predicted labels: archery\n",
      "2 sec Top 1 predicted labels: archery\n",
      "3 sec Top 1 predicted labels: archery\n",
      "4 sec Top 1 predicted labels: archery\n",
      "5 sec Top 1 predicted labels: archery\n",
      "6 sec Top 1 predicted labels: archery\n",
      "7 sec Top 1 predicted labels: archery\n",
      "8 sec Top 1 predicted labels: archery\n",
      "9 sec Top 1 predicted labels: archery\n",
      "end of prediction\n"
     ]
    }
   ],
   "source": [
    "video = EncodedVideo.from_path(video_path)\n",
    "\n",
    "start_sec = 0\n",
    "\n",
    "while True:\n",
    "    if start_sec == 9:\n",
    "        print('end of prediction')\n",
    "        break;\n",
    "    start_sec = start_sec + 1\n",
    "    end_sec = start_sec + clip_duration\n",
    "\n",
    "    video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
    "    video_data = transform(video_data)\n",
    "    inputs = video_data[\"video\"]\n",
    "    inputs = [i.to(device)[None, ...] for i in inputs]\n",
    "\n",
    "    preds = model(inputs)\n",
    "\n",
    "    post_act = torch.nn.Softmax(dim=1)\n",
    "    preds = post_act(preds)\n",
    "    pred_classes = preds.topk(k=1).indices[0]\n",
    "\n",
    "    # Map the predicted classes to the label names\n",
    "    pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes]\n",
    "    print(start_sec,\"sec\",\"Top 1 predicted labels: %s\" % \", \".join(pred_class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test Slowfast with Custom data\n",
    "\n",
    "Kinetics 400에 대해 pretrained 된 slowfast 모델이 UCF 101 dataset에 대해서도 어느정도 잘 동작함을 확인하였다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Frame width: 320\n",
      "Frame height: 240\n",
      "Frame count: 171\n",
      "FPS: 29.97002997002997\n"
     ]
    }
   ],
   "source": [
    "# step1.opencv 라이브러리 불러오기\n",
    "import cv2\n",
    "\n",
    "# step2.영상 파일 열기\n",
    "cap = cv2.VideoCapture('Basketball_1.avi')\n",
    "\n",
    "# step3.영상의 가로, 세로 사이즈, 전체 프레임수, FPS 등을 출력\n",
    "print('Frame width:', int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)))\n",
    "print('Frame height:', int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT)))\n",
    "print('Frame count:', int(cap.get(cv2.CAP_PROP_FRAME_COUNT)))\n",
    "print('FPS:', cap.get(cv2.CAP_PROP_FPS))\n",
    "\n",
    "# step4.영상 닫고 모든창 종료\n",
    "cap.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_sec = 0\n",
    "end_sec = start_sec + clip_duration\n",
    "\n",
    "# Initialize an EncodedVideo helper class and load the video\n",
    "video = EncodedVideo.from_path('Basketball_1.mp4')\n",
    "\n",
    "# Load the desired clip\n",
    "video_data = video.get_clip(start_sec=start_sec, end_sec=end_sec)\n",
    "\n",
    "# Apply a transform to normalize the video input\n",
    "video_data = transform(video_data)\n",
    "\n",
    "# Move the inputs to the desired device\n",
    "inputs = video_data[\"video\"]\n",
    "inputs = [i.to(device)[None, ...] for i in inputs]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "slow pathway : torch.Size([1, 3, 8, 256, 256])\n",
      "fast pathway : torch.Size([1, 3, 32, 256, 256])\n"
     ]
    }
   ],
   "source": [
    "print('slow pathway :',inputs[0].shape)\n",
    "print('fast pathway :',inputs[1].shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Top 5 predicted labels: shooting basketball, dunking basketball, playing basketball, dribbling basketball, passing American football (not in game)\n"
     ]
    }
   ],
   "source": [
    "# Pass the input clip through the model\n",
    "preds = model(inputs)\n",
    "\n",
    "# Get the predicted classes\n",
    "post_act = torch.nn.Softmax(dim=1)\n",
    "preds = post_act(preds)\n",
    "pred_classes = preds.topk(k=5).indices[0]\n",
    "\n",
    "# Map the predicted classes to the label names\n",
    "pred_class_names = [kinetics_id_to_classname[int(i)] for i in pred_classes]\n",
    "print(\"Top 5 predicted labels: %s\" % \", \".join(pred_class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### fine tuning with custom data\n",
    "\n",
    "kinetics 400에 대해 pretrained 된 slowfast 모델을 custom data에 대해 fine tuning 하겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in C:\\Users\\jlee0/.cache\\torch\\hub\\facebookresearch_pytorchvideo_main\n"
     ]
    }
   ],
   "source": [
    "# Choose the `slowfast_r50` model \n",
    "model = torch.hub.load('facebookresearch/pytorchvideo', 'slowfast_r50', pretrained=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "=====================================================================================\n",
       "Layer (type:depth-idx)                                       Param #\n",
       "=====================================================================================\n",
       "Net                                                          --\n",
       "├─ModuleList: 1-1                                            --\n",
       "│    └─MultiPathWayWithFuse: 2-1                             --\n",
       "│    │    └─ModuleList: 3-1                                  15,432\n",
       "│    │    └─FuseFastToSlow: 3-2                              928\n",
       "│    └─MultiPathWayWithFuse: 2-2                             --\n",
       "│    │    └─ModuleList: 3-3                                  225,760\n",
       "│    │    └─FuseFastToSlow: 3-4                              14,464\n",
       "│    └─MultiPathWayWithFuse: 2-3                             --\n",
       "│    │    └─ModuleList: 3-5                                  1,287,552\n",
       "│    │    └─FuseFastToSlow: 3-6                              57,600\n",
       "│    └─MultiPathWayWithFuse: 2-4                             --\n",
       "│    │    └─ModuleList: 3-7                                  10,369,536\n",
       "│    │    └─FuseFastToSlow: 3-8                              229,888\n",
       "│    └─MultiPathWayWithFuse: 2-5                             --\n",
       "│    │    └─ModuleList: 3-9                                  21,443,328\n",
       "│    │    └─Identity: 3-10                                   --\n",
       "│    └─PoolConcatPathway: 2-6                                --\n",
       "│    │    └─ModuleList: 3-11                                 --\n",
       "│    └─ResNetBasicHead: 2-7                                  --\n",
       "│    │    └─Dropout: 3-12                                    --\n",
       "│    │    └─Linear: 3-13                                     922,000\n",
       "│    │    └─AdaptiveAvgPool3d: 3-14                          --\n",
       "=====================================================================================\n",
       "Total params: 34,566,488\n",
       "Trainable params: 34,566,488\n",
       "Non-trainable params: 0\n",
       "====================================================================================="
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from torchinfo import summary\n",
    "\n",
    "summary(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (blocks): ModuleList(\n",
      "    (0): MultiPathWayWithFuse(\n",
      "      (multipathway_blocks): ModuleList(\n",
      "        (0): ResNetBasicStem(\n",
      "          (conv): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
      "          (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU()\n",
      "          (pool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): ResNetBasicStem(\n",
      "          (conv): Conv3d(3, 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "          (norm): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU()\n",
      "          (pool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (multipathway_fusion): FuseFastToSlow(\n",
      "        (conv_fast_to_slow): Conv3d(8, 16, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
      "        (norm): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): MultiPathWayWithFuse(\n",
      "      (multipathway_blocks): ModuleList(\n",
      "        (0): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(80, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(8, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(32, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(32, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (multipathway_fusion): FuseFastToSlow(\n",
      "        (conv_fast_to_slow): Conv3d(32, 64, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
      "        (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): MultiPathWayWithFuse(\n",
      "      (multipathway_blocks): ModuleList(\n",
      "        (0): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (3): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(32, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (3): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (multipathway_fusion): FuseFastToSlow(\n",
      "        (conv_fast_to_slow): Conv3d(64, 128, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
      "        (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (3): MultiPathWayWithFuse(\n",
      "      (multipathway_blocks): ModuleList(\n",
      "        (0): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(640, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (3): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (4): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (5): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(64, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (3): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (4): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (5): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (multipathway_fusion): FuseFastToSlow(\n",
      "        (conv_fast_to_slow): Conv3d(128, 256, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
      "        (norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (4): MultiPathWayWithFuse(\n",
      "      (multipathway_blocks): ModuleList(\n",
      "        (0): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1280, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (multipathway_fusion): Identity()\n",
      "    )\n",
      "    (5): PoolConcatPathway(\n",
      "      (pool): ModuleList(\n",
      "        (0): AvgPool3d(kernel_size=(8, 7, 7), stride=(1, 1, 1), padding=(0, 0, 0))\n",
      "        (1): AvgPool3d(kernel_size=(32, 7, 7), stride=(1, 1, 1), padding=(0, 0, 0))\n",
      "      )\n",
      "    )\n",
      "    (6): ResNetBasicHead(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (proj): Linear(in_features=2304, out_features=400, bias=True)\n",
      "      (output_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Modify fc layer\n",
    "\n",
    "기존 slowfast fc layer(2304,400)을 이진 분류 모델에 맞게 (2304,2)로 수정한다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# freezing\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(model.blocks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Linear(in_features=2304, out_features=400, bias=True)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.blocks[6].proj"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "classes = ('basketball', 'not-basketball') #basketball인지 아닌지 분류하는 이진 분류 문제\n",
    "\n",
    "# fc layer 수정\n",
    "fc_in_features = model.blocks[6].proj.in_features\n",
    "model.blocks[6].proj = nn.Linear(fc_in_features, len(classes))\n",
    "model = model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Net(\n",
      "  (blocks): ModuleList(\n",
      "    (0): MultiPathWayWithFuse(\n",
      "      (multipathway_blocks): ModuleList(\n",
      "        (0): ResNetBasicStem(\n",
      "          (conv): Conv3d(3, 64, kernel_size=(1, 7, 7), stride=(1, 2, 2), padding=(0, 3, 3), bias=False)\n",
      "          (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU()\n",
      "          (pool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
      "        )\n",
      "        (1): ResNetBasicStem(\n",
      "          (conv): Conv3d(3, 8, kernel_size=(5, 7, 7), stride=(1, 2, 2), padding=(2, 3, 3), bias=False)\n",
      "          (norm): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "          (activation): ReLU()\n",
      "          (pool): MaxPool3d(kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=[0, 1, 1], dilation=1, ceil_mode=False)\n",
      "        )\n",
      "      )\n",
      "      (multipathway_fusion): FuseFastToSlow(\n",
      "        (conv_fast_to_slow): Conv3d(8, 16, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
      "        (norm): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (1): MultiPathWayWithFuse(\n",
      "      (multipathway_blocks): ModuleList(\n",
      "        (0): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(80, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(80, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(256, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(8, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(32, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(32, 8, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(8, 8, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(8, 32, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (multipathway_fusion): FuseFastToSlow(\n",
      "        (conv_fast_to_slow): Conv3d(32, 64, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
      "        (norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (2): MultiPathWayWithFuse(\n",
      "      (multipathway_blocks): ModuleList(\n",
      "        (0): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(320, 512, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(320, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (3): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(512, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_a): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(128, 128, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(128, 512, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(32, 64, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(32, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (3): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(64, 16, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(16, 16, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(16, 64, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (multipathway_fusion): FuseFastToSlow(\n",
      "        (conv_fast_to_slow): Conv3d(64, 128, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
      "        (norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (3): MultiPathWayWithFuse(\n",
      "      (multipathway_blocks): ModuleList(\n",
      "        (0): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(640, 1024, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(640, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (3): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (4): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (5): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1024, 256, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(256, 256, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(256, 1024, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(64, 128, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(64, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (3): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (4): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (5): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 32, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(32, 32, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(32, 128, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (multipathway_fusion): FuseFastToSlow(\n",
      "        (conv_fast_to_slow): Conv3d(128, 256, kernel_size=(7, 1, 1), stride=(4, 1, 1), padding=(3, 0, 0), bias=False)\n",
      "        (norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "        (activation): ReLU()\n",
      "      )\n",
      "    )\n",
      "    (4): MultiPathWayWithFuse(\n",
      "      (multipathway_blocks): ModuleList(\n",
      "        (0): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(1280, 2048, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(1280, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(2048, 512, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(512, 512, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(512, 2048, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(2048, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResStage(\n",
      "          (res_blocks): ModuleList(\n",
      "            (0): ResBlock(\n",
      "              (branch1_conv): Conv3d(128, 256, kernel_size=(1, 1, 1), stride=(1, 2, 2), bias=False)\n",
      "              (branch1_norm): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(128, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 2, 2), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (1): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "            (2): ResBlock(\n",
      "              (branch2): BottleneckBlock(\n",
      "                (conv_a): Conv3d(256, 64, kernel_size=(3, 1, 1), stride=(1, 1, 1), padding=(1, 0, 0), bias=False)\n",
      "                (norm_a): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_a): ReLU()\n",
      "                (conv_b): Conv3d(64, 64, kernel_size=(1, 3, 3), stride=(1, 1, 1), padding=(0, 1, 1), bias=False)\n",
      "                (norm_b): BatchNorm3d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "                (act_b): ReLU()\n",
      "                (conv_c): Conv3d(64, 256, kernel_size=(1, 1, 1), stride=(1, 1, 1), bias=False)\n",
      "                (norm_c): BatchNorm3d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "              )\n",
      "              (activation): ReLU()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (multipathway_fusion): Identity()\n",
      "    )\n",
      "    (5): PoolConcatPathway(\n",
      "      (pool): ModuleList(\n",
      "        (0): AvgPool3d(kernel_size=(8, 7, 7), stride=(1, 1, 1), padding=(0, 0, 0))\n",
      "        (1): AvgPool3d(kernel_size=(32, 7, 7), stride=(1, 1, 1), padding=(0, 0, 0))\n",
      "      )\n",
      "    )\n",
      "    (6): ResNetBasicHead(\n",
      "      (dropout): Dropout(p=0.5, inplace=False)\n",
      "      (proj): Linear(in_features=2304, out_features=2, bias=True)\n",
      "      (output_pool): AdaptiveAvgPool3d(output_size=1)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model) #fc layer(out_features = 2)로 수정 완료"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create dataset\n",
    "\n",
    "이진 분류를 위한 데이터 셋을 구축한다.\n",
    "\n",
    "dataset은 UCF101의 basketball, boxing video로 이루어져 있으며, basketball 영상인지 아닌지를 분류하는 것을 목표로 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jlee0\\Desktop\\KYU\\hanim ict\\테트라부이&테트라인\\추락감지 모델\\dataset_prac\\train\n"
     ]
    }
   ],
   "source": [
    "cd dataset_prac/train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "metadata = pd.read_csv('metadata_train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>video_name</th>\n",
       "      <th>preds</th>\n",
       "      <th>video_path</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>train_0.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&amp;테트라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>train_1.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&amp;테트라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>train_2.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&amp;테트라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>train_3.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&amp;테트라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>train_4.avi</td>\n",
       "      <td>1</td>\n",
       "      <td>C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&amp;테트라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>208</th>\n",
       "      <td>train_208.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&amp;테트라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>209</th>\n",
       "      <td>train_209.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&amp;테트라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>210</th>\n",
       "      <td>train_210.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&amp;테트라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>211</th>\n",
       "      <td>train_211.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&amp;테트라...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>212</th>\n",
       "      <td>train_212.avi</td>\n",
       "      <td>0</td>\n",
       "      <td>C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&amp;테트라...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>213 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        video_name  preds                                         video_path\n",
       "0      train_0.avi      1  C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&테트라...\n",
       "1      train_1.avi      1  C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&테트라...\n",
       "2      train_2.avi      1  C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&테트라...\n",
       "3      train_3.avi      1  C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&테트라...\n",
       "4      train_4.avi      1  C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&테트라...\n",
       "..             ...    ...                                                ...\n",
       "208  train_208.avi      0  C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&테트라...\n",
       "209  train_209.avi      0  C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&테트라...\n",
       "210  train_210.avi      0  C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&테트라...\n",
       "211  train_211.avi      0  C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&테트라...\n",
       "212  train_212.avi      0  C:/Users/jlee0/Desktop/KYU/hanim ict/테트라부이&테트라...\n",
       "\n",
       "[213 rows x 3 columns]"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "213"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train = metadata\n",
    "\n",
    "len(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "side_size = 256 #원하는 video size\n",
    "mean = [0.45, 0.45, 0.45] #정규화를 위한 mean 정의\n",
    "std = [0.225, 0.225, 0.225] #정규화를 위한 std 정의\n",
    "crop_size = 256 #원하는 video size\n",
    "num_frames = 32 #샘플링을 위한 frames 정의\n",
    "sampling_rate = 2 #input clip의 길이를 정의하기 위해 사용\n",
    "frames_per_second = 30 #영상의 기본 fps\n",
    "slowfast_alpha = 4 #slow path와 fast path의 frames 비율을 정해주기 위해 사용\n",
    "num_clips = 10\n",
    "num_crops = 3\n",
    "\n",
    "\n",
    "class PackPathway(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Transform for converting video frames as a list of tensors. \n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        \n",
    "    def forward(self, frames: torch.Tensor):\n",
    "        fast_pathway = frames\n",
    "        # Perform temporal sampling from the fast pathway.\n",
    "        slow_pathway = torch.index_select(\n",
    "            frames,\n",
    "            1,\n",
    "            torch.linspace(\n",
    "                0, frames.shape[1] - 1, frames.shape[1] // slowfast_alpha\n",
    "            ).long(),\n",
    "        )\n",
    "        frame_list = [slow_pathway, fast_pathway]\n",
    "        return frame_list\n",
    "\n",
    "    \n",
    "transform =  ApplyTransformToKey(\n",
    "    key=\"video\",\n",
    "    transform=Compose(\n",
    "        [\n",
    "            UniformTemporalSubsample(num_frames),\n",
    "            Lambda(lambda x: x/255.0),\n",
    "            NormalizeVideo(mean, std), #비디오 정규화, 각 채널(=3)에 대해 적용된다\n",
    "            ShortSideScale(\n",
    "                size=side_size\n",
    "            ),\n",
    "            CenterCropVideo(crop_size),\n",
    "            PackPathway()\n",
    "        ]\n",
    "    ),\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset, DataLoader\n",
    "\n",
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,metadata,transform=None):\n",
    "        self.metadata = metadata\n",
    "        \n",
    "        self.video_path_list = metadata['video_path']\n",
    "        self.video_class_list = metadata['preds']\n",
    "        \n",
    "        self.transform = transform\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(metadata)\n",
    "    \n",
    "    def __getitem__(self,idx):\n",
    "        video_path = self.video_path_list[idx]\n",
    "        video_class = self.video_class_list[idx]\n",
    "        \n",
    "        video = EncodedVideo.from_path(video_path)\n",
    "        \n",
    "        if self.transform is not None:\n",
    "            video_data = video.get_clip(start_sec=1, end_sec=2)\n",
    "\n",
    "            video_data = transform(video_data)\n",
    "            \n",
    "            inputs = video_data[\"video\"]\n",
    "            inputs = [i.to(device)[None, ...] for i in inputs]\n",
    "            \n",
    "        return inputs, video_class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(metadata=metadata,transform=transform)\n",
    "trainloader = DataLoader(dataset=dataset,\n",
    "                        batch_size=10,\n",
    "                        shuffle=True,\n",
    "                        drop_last=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training model\n",
    "\n",
    "구축된 데이터 셋을 통해 UCF101에 대한 Slowfast 모델을 fine-tunning 한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import optim\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001,\n",
    "                      momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=200)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(epoch, model, criterion, optimizer):\n",
    "    model.train()\n",
    "    train_loss = 0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    for batch_idx, (videos, labels) in enumerate(tqdm(trainloader)):\n",
    "        fuse = []\n",
    "        for _, X in enumerate(videos):\n",
    "            X = X.reshape((-1,) + X.shape[2:])\n",
    "            fuse.append(X)\n",
    "        \n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        preds = model(fuse)\n",
    "        post_act = torch.nn.Softmax(dim=1)\n",
    "        preds = post_act(preds)\n",
    "        #outputs = torch.argmax(preds,dim = 1)\n",
    "        \n",
    "        loss = criterion(preds, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        train_loss += loss.item()*videos[0].shape[0]\n",
    "        _, predicted = preds.max(1)\n",
    "        total += labels.size(0)\n",
    "        correct += predicted.eq(labels).sum().item()\n",
    "    \n",
    "    epoch_loss = train_loss/total\n",
    "    epoch_acc = correct/total*100\n",
    "    print(\"Train | Loss:%.4f Acc: %.2f%% (%s/%s)\" \n",
    "        % (epoch_loss, epoch_acc, correct, total))\n",
    "    return epoch_loss, epoch_acc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:25<08:50, 25.28s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:50<08:26, 25.32s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [01:15<07:58, 25.17s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [01:40<07:31, 25.09s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [02:05<07:05, 25.01s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [02:30<06:40, 25.03s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [02:55<06:15, 25.05s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [03:20<05:50, 25.02s/it]\u001b[A\n",
      " 41%|████      | 9/22 [03:45<05:26, 25.08s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [04:10<05:02, 25.17s/it]\u001b[A\n",
      " 50%|█████     | 11/22 [04:35<04:35, 25.08s/it]\u001b[A\n",
      " 55%|█████▍    | 12/22 [05:00<04:10, 25.05s/it]\u001b[A\n",
      " 59%|█████▉    | 13/22 [05:27<03:49, 25.48s/it]\u001b[A\n",
      " 64%|██████▎   | 14/22 [05:54<03:29, 26.15s/it]\u001b[A\n",
      " 68%|██████▊   | 15/22 [06:23<03:07, 26.81s/it]\u001b[A\n",
      " 73%|███████▎  | 16/22 [06:49<02:40, 26.67s/it]\u001b[A\n",
      " 77%|███████▋  | 17/22 [07:15<02:12, 26.52s/it]\u001b[A\n",
      " 82%|████████▏ | 18/22 [07:41<01:45, 26.33s/it]\u001b[A\n",
      " 86%|████████▋ | 19/22 [08:07<01:18, 26.16s/it]\u001b[A\n",
      " 91%|█████████ | 20/22 [08:33<00:52, 26.01s/it]\u001b[A\n",
      " 95%|█████████▌| 21/22 [08:59<00:25, 25.98s/it]\u001b[A\n",
      "100%|██████████| 22/22 [09:07<00:00, 24.87s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | Loss:0.3684 Acc: 100.00% (213/213)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  0%|          | 0/22 [00:00<?, ?it/s]\u001b[A"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "  5%|▍         | 1/22 [00:26<09:26, 26.96s/it]\u001b[A\n",
      "  9%|▉         | 2/22 [00:52<08:53, 26.68s/it]\u001b[A\n",
      " 14%|█▎        | 3/22 [01:18<08:22, 26.45s/it]\u001b[A\n",
      " 18%|█▊        | 4/22 [01:45<07:59, 26.64s/it]\u001b[A\n",
      " 23%|██▎       | 5/22 [02:11<07:27, 26.30s/it]\u001b[A\n",
      " 27%|██▋       | 6/22 [02:37<06:57, 26.08s/it]\u001b[A\n",
      " 32%|███▏      | 7/22 [03:02<06:28, 25.92s/it]\u001b[A\n",
      " 36%|███▋      | 8/22 [03:29<06:05, 26.08s/it]\u001b[A\n",
      " 41%|████      | 9/22 [03:54<05:38, 26.01s/it]\u001b[A\n",
      " 45%|████▌     | 10/22 [04:20<05:10, 25.87s/it]\u001b[A\n",
      " 50%|█████     | 11/22 [04:46<04:45, 25.95s/it]\u001b[A\n",
      " 55%|█████▍    | 12/22 [05:11<04:17, 25.73s/it]\u001b[A\n",
      " 59%|█████▉    | 13/22 [05:37<03:51, 25.69s/it]\u001b[A\n",
      " 64%|██████▎   | 14/22 [06:03<03:25, 25.66s/it]\u001b[A\n",
      " 68%|██████▊   | 15/22 [06:29<03:00, 25.77s/it]\u001b[A\n",
      " 73%|███████▎  | 16/22 [06:56<02:36, 26.14s/it]\u001b[A\n",
      " 77%|███████▋  | 17/22 [07:22<02:10, 26.10s/it]\u001b[A\n",
      " 82%|████████▏ | 18/22 [07:47<01:43, 25.85s/it]\u001b[A\n",
      " 86%|████████▋ | 19/22 [08:13<01:17, 25.82s/it]\u001b[A\n",
      " 91%|█████████ | 20/22 [08:39<00:51, 25.93s/it]\u001b[A\n",
      " 95%|█████████▌| 21/22 [09:04<00:25, 25.84s/it]\u001b[A\n",
      "100%|██████████| 22/22 [09:12<00:00, 25.13s/it]\u001b[A\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train | Loss:0.3576 Acc: 100.00% (213/213)\n",
      "**Learning time: 18m 21s\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import copy\n",
    "\n",
    "start_time = time.time()\n",
    "best_acc = 0\n",
    "epoch_length = 2\n",
    "save_loss = {\"train\":[]}\n",
    "save_acc = {\"train\":[]}\n",
    "for epoch in range(epoch_length):\n",
    "    print(\"Epoch %s\" % epoch)\n",
    "    train_loss, train_acc = train(epoch, model, criterion, optimizer)\n",
    "    save_loss['train'].append(train_loss)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    # Save model\n",
    "    if train_acc > best_acc:\n",
    "        best_acc = train_acc\n",
    "        best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "learning_time = time.time() - start_time\n",
    "print(f'**Learning time: {learning_time // 60:.0f}m {learning_time % 60:.0f}s')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model's state_dict:\n",
      "blocks.0.multipathway_blocks.0.conv.weight \t torch.Size([64, 3, 1, 7, 7])\n",
      "blocks.0.multipathway_blocks.0.norm.weight \t torch.Size([64])\n",
      "blocks.0.multipathway_blocks.0.norm.bias \t torch.Size([64])\n",
      "blocks.0.multipathway_blocks.0.norm.running_mean \t torch.Size([64])\n",
      "blocks.0.multipathway_blocks.0.norm.running_var \t torch.Size([64])\n",
      "blocks.0.multipathway_blocks.0.norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.0.multipathway_blocks.1.conv.weight \t torch.Size([8, 3, 5, 7, 7])\n",
      "blocks.0.multipathway_blocks.1.norm.weight \t torch.Size([8])\n",
      "blocks.0.multipathway_blocks.1.norm.bias \t torch.Size([8])\n",
      "blocks.0.multipathway_blocks.1.norm.running_mean \t torch.Size([8])\n",
      "blocks.0.multipathway_blocks.1.norm.running_var \t torch.Size([8])\n",
      "blocks.0.multipathway_blocks.1.norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.0.multipathway_fusion.conv_fast_to_slow.weight \t torch.Size([16, 8, 7, 1, 1])\n",
      "blocks.0.multipathway_fusion.norm.weight \t torch.Size([16])\n",
      "blocks.0.multipathway_fusion.norm.bias \t torch.Size([16])\n",
      "blocks.0.multipathway_fusion.norm.running_mean \t torch.Size([16])\n",
      "blocks.0.multipathway_fusion.norm.running_var \t torch.Size([16])\n",
      "blocks.0.multipathway_fusion.norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch1_conv.weight \t torch.Size([256, 80, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch1_norm.weight \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch1_norm.bias \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch1_norm.running_mean \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch1_norm.running_var \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch1_norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.conv_a.weight \t torch.Size([64, 80, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_a.weight \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_a.bias \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_a.running_mean \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_a.running_var \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.conv_b.weight \t torch.Size([64, 64, 1, 3, 3])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_b.weight \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_b.bias \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_b.running_mean \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_b.running_var \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.conv_c.weight \t torch.Size([256, 64, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_c.weight \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_c.bias \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_c.running_mean \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_c.running_var \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.0.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.conv_a.weight \t torch.Size([64, 256, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_a.weight \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_a.bias \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_a.running_mean \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_a.running_var \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.conv_b.weight \t torch.Size([64, 64, 1, 3, 3])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_b.weight \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_b.bias \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_b.running_mean \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_b.running_var \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.conv_c.weight \t torch.Size([256, 64, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_c.weight \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_c.bias \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_c.running_mean \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_c.running_var \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.1.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.conv_a.weight \t torch.Size([64, 256, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_a.weight \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_a.bias \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_a.running_mean \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_a.running_var \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.conv_b.weight \t torch.Size([64, 64, 1, 3, 3])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_b.weight \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_b.bias \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_b.running_mean \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_b.running_var \t torch.Size([64])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.conv_c.weight \t torch.Size([256, 64, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_c.weight \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_c.bias \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_c.running_mean \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_c.running_var \t torch.Size([256])\n",
      "blocks.1.multipathway_blocks.0.res_blocks.2.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch1_conv.weight \t torch.Size([32, 8, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch1_norm.weight \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch1_norm.bias \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch1_norm.running_mean \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch1_norm.running_var \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch1_norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.conv_a.weight \t torch.Size([8, 8, 3, 1, 1])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_a.weight \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_a.bias \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_a.running_mean \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_a.running_var \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.conv_b.weight \t torch.Size([8, 8, 1, 3, 3])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_b.weight \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_b.bias \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_b.running_mean \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_b.running_var \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.conv_c.weight \t torch.Size([32, 8, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_c.weight \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_c.bias \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_c.running_mean \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_c.running_var \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.0.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.conv_a.weight \t torch.Size([8, 32, 3, 1, 1])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_a.weight \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_a.bias \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_a.running_mean \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_a.running_var \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.conv_b.weight \t torch.Size([8, 8, 1, 3, 3])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_b.weight \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_b.bias \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_b.running_mean \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_b.running_var \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.conv_c.weight \t torch.Size([32, 8, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_c.weight \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_c.bias \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_c.running_mean \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_c.running_var \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.1.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.conv_a.weight \t torch.Size([8, 32, 3, 1, 1])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_a.weight \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_a.bias \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_a.running_mean \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_a.running_var \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.conv_b.weight \t torch.Size([8, 8, 1, 3, 3])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_b.weight \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_b.bias \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_b.running_mean \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_b.running_var \t torch.Size([8])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.conv_c.weight \t torch.Size([32, 8, 1, 1, 1])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_c.weight \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_c.bias \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_c.running_mean \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_c.running_var \t torch.Size([32])\n",
      "blocks.1.multipathway_blocks.1.res_blocks.2.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.1.multipathway_fusion.conv_fast_to_slow.weight \t torch.Size([64, 32, 7, 1, 1])\n",
      "blocks.1.multipathway_fusion.norm.weight \t torch.Size([64])\n",
      "blocks.1.multipathway_fusion.norm.bias \t torch.Size([64])\n",
      "blocks.1.multipathway_fusion.norm.running_mean \t torch.Size([64])\n",
      "blocks.1.multipathway_fusion.norm.running_var \t torch.Size([64])\n",
      "blocks.1.multipathway_fusion.norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch1_conv.weight \t torch.Size([512, 320, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch1_norm.weight \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch1_norm.bias \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch1_norm.running_mean \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch1_norm.running_var \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch1_norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.conv_a.weight \t torch.Size([128, 320, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_a.weight \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_a.bias \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_a.running_mean \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_a.running_var \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.conv_b.weight \t torch.Size([128, 128, 1, 3, 3])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_b.weight \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_b.bias \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_b.running_mean \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_b.running_var \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.conv_c.weight \t torch.Size([512, 128, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_c.weight \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_c.bias \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_c.running_mean \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_c.running_var \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.0.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.conv_a.weight \t torch.Size([128, 512, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_a.weight \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_a.bias \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_a.running_mean \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_a.running_var \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.conv_b.weight \t torch.Size([128, 128, 1, 3, 3])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_b.weight \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_b.bias \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_b.running_mean \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_b.running_var \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.conv_c.weight \t torch.Size([512, 128, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_c.weight \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_c.bias \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_c.running_mean \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_c.running_var \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.1.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.conv_a.weight \t torch.Size([128, 512, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_a.weight \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_a.bias \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_a.running_mean \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_a.running_var \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.conv_b.weight \t torch.Size([128, 128, 1, 3, 3])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_b.weight \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_b.bias \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_b.running_mean \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_b.running_var \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.conv_c.weight \t torch.Size([512, 128, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_c.weight \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_c.bias \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_c.running_mean \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_c.running_var \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.2.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.conv_a.weight \t torch.Size([128, 512, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_a.weight \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_a.bias \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_a.running_mean \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_a.running_var \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.conv_b.weight \t torch.Size([128, 128, 1, 3, 3])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_b.weight \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_b.bias \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_b.running_mean \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_b.running_var \t torch.Size([128])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.conv_c.weight \t torch.Size([512, 128, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_c.weight \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_c.bias \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_c.running_mean \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_c.running_var \t torch.Size([512])\n",
      "blocks.2.multipathway_blocks.0.res_blocks.3.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch1_conv.weight \t torch.Size([64, 32, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch1_norm.weight \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch1_norm.bias \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch1_norm.running_mean \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch1_norm.running_var \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch1_norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.conv_a.weight \t torch.Size([16, 32, 3, 1, 1])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_a.weight \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_a.bias \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_a.running_mean \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_a.running_var \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.conv_b.weight \t torch.Size([16, 16, 1, 3, 3])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_b.weight \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_b.bias \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_b.running_mean \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_b.running_var \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.conv_c.weight \t torch.Size([64, 16, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_c.weight \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_c.bias \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_c.running_mean \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_c.running_var \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.0.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.conv_a.weight \t torch.Size([16, 64, 3, 1, 1])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_a.weight \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_a.bias \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_a.running_mean \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_a.running_var \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.conv_b.weight \t torch.Size([16, 16, 1, 3, 3])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_b.weight \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_b.bias \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_b.running_mean \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_b.running_var \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.conv_c.weight \t torch.Size([64, 16, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_c.weight \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_c.bias \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_c.running_mean \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_c.running_var \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.1.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.conv_a.weight \t torch.Size([16, 64, 3, 1, 1])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_a.weight \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_a.bias \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_a.running_mean \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_a.running_var \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.conv_b.weight \t torch.Size([16, 16, 1, 3, 3])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_b.weight \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_b.bias \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_b.running_mean \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_b.running_var \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.conv_c.weight \t torch.Size([64, 16, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_c.weight \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_c.bias \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_c.running_mean \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_c.running_var \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.2.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.conv_a.weight \t torch.Size([16, 64, 3, 1, 1])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_a.weight \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_a.bias \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_a.running_mean \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_a.running_var \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.conv_b.weight \t torch.Size([16, 16, 1, 3, 3])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_b.weight \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_b.bias \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_b.running_mean \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_b.running_var \t torch.Size([16])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.conv_c.weight \t torch.Size([64, 16, 1, 1, 1])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_c.weight \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_c.bias \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_c.running_mean \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_c.running_var \t torch.Size([64])\n",
      "blocks.2.multipathway_blocks.1.res_blocks.3.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.2.multipathway_fusion.conv_fast_to_slow.weight \t torch.Size([128, 64, 7, 1, 1])\n",
      "blocks.2.multipathway_fusion.norm.weight \t torch.Size([128])\n",
      "blocks.2.multipathway_fusion.norm.bias \t torch.Size([128])\n",
      "blocks.2.multipathway_fusion.norm.running_mean \t torch.Size([128])\n",
      "blocks.2.multipathway_fusion.norm.running_var \t torch.Size([128])\n",
      "blocks.2.multipathway_fusion.norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch1_conv.weight \t torch.Size([1024, 640, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch1_norm.weight \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch1_norm.bias \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch1_norm.running_mean \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch1_norm.running_var \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch1_norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.conv_a.weight \t torch.Size([256, 640, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_a.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_a.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_a.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_a.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.conv_b.weight \t torch.Size([256, 256, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_b.weight \t torch.Size([256])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_b.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_b.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_b.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.conv_c.weight \t torch.Size([1024, 256, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_c.weight \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_c.bias \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_c.running_mean \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_c.running_var \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.0.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.conv_a.weight \t torch.Size([256, 1024, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_a.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_a.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_a.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_a.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.conv_b.weight \t torch.Size([256, 256, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_b.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_b.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_b.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_b.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.conv_c.weight \t torch.Size([1024, 256, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_c.weight \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_c.bias \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_c.running_mean \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_c.running_var \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.1.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.conv_a.weight \t torch.Size([256, 1024, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_a.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_a.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_a.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_a.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.conv_b.weight \t torch.Size([256, 256, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_b.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_b.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_b.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_b.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.conv_c.weight \t torch.Size([1024, 256, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_c.weight \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_c.bias \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_c.running_mean \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_c.running_var \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.2.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.conv_a.weight \t torch.Size([256, 1024, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_a.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_a.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_a.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_a.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.conv_b.weight \t torch.Size([256, 256, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_b.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_b.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_b.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_b.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.conv_c.weight \t torch.Size([1024, 256, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_c.weight \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_c.bias \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_c.running_mean \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_c.running_var \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.3.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.conv_a.weight \t torch.Size([256, 1024, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_a.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_a.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_a.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_a.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.conv_b.weight \t torch.Size([256, 256, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_b.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_b.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_b.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_b.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.conv_c.weight \t torch.Size([1024, 256, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_c.weight \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_c.bias \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_c.running_mean \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_c.running_var \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.4.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.conv_a.weight \t torch.Size([256, 1024, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_a.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_a.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_a.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_a.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.conv_b.weight \t torch.Size([256, 256, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_b.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_b.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_b.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_b.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.conv_c.weight \t torch.Size([1024, 256, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_c.weight \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_c.bias \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_c.running_mean \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_c.running_var \t torch.Size([1024])\n",
      "blocks.3.multipathway_blocks.0.res_blocks.5.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch1_conv.weight \t torch.Size([128, 64, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch1_norm.weight \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch1_norm.bias \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch1_norm.running_mean \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch1_norm.running_var \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch1_norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.conv_a.weight \t torch.Size([32, 64, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_a.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_a.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_a.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_a.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_a.num_batches_tracked \t torch.Size([])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.conv_b.weight \t torch.Size([32, 32, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_b.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_b.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_b.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_b.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.conv_c.weight \t torch.Size([128, 32, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_c.weight \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_c.bias \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_c.running_mean \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_c.running_var \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.0.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.conv_a.weight \t torch.Size([32, 128, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_a.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_a.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_a.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_a.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.conv_b.weight \t torch.Size([32, 32, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_b.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_b.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_b.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_b.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.conv_c.weight \t torch.Size([128, 32, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_c.weight \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_c.bias \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_c.running_mean \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_c.running_var \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.1.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.conv_a.weight \t torch.Size([32, 128, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_a.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_a.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_a.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_a.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.conv_b.weight \t torch.Size([32, 32, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_b.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_b.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_b.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_b.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.conv_c.weight \t torch.Size([128, 32, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_c.weight \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_c.bias \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_c.running_mean \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_c.running_var \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.2.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.conv_a.weight \t torch.Size([32, 128, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_a.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_a.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_a.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_a.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.conv_b.weight \t torch.Size([32, 32, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_b.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_b.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_b.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_b.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.conv_c.weight \t torch.Size([128, 32, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_c.weight \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_c.bias \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_c.running_mean \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_c.running_var \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.3.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.conv_a.weight \t torch.Size([32, 128, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_a.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_a.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_a.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_a.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.conv_b.weight \t torch.Size([32, 32, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_b.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_b.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_b.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_b.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.conv_c.weight \t torch.Size([128, 32, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_c.weight \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_c.bias \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_c.running_mean \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_c.running_var \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.4.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.conv_a.weight \t torch.Size([32, 128, 3, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_a.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_a.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_a.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_a.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.conv_b.weight \t torch.Size([32, 32, 1, 3, 3])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_b.weight \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_b.bias \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_b.running_mean \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_b.running_var \t torch.Size([32])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.conv_c.weight \t torch.Size([128, 32, 1, 1, 1])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_c.weight \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_c.bias \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_c.running_mean \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_c.running_var \t torch.Size([128])\n",
      "blocks.3.multipathway_blocks.1.res_blocks.5.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.3.multipathway_fusion.conv_fast_to_slow.weight \t torch.Size([256, 128, 7, 1, 1])\n",
      "blocks.3.multipathway_fusion.norm.weight \t torch.Size([256])\n",
      "blocks.3.multipathway_fusion.norm.bias \t torch.Size([256])\n",
      "blocks.3.multipathway_fusion.norm.running_mean \t torch.Size([256])\n",
      "blocks.3.multipathway_fusion.norm.running_var \t torch.Size([256])\n",
      "blocks.3.multipathway_fusion.norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch1_conv.weight \t torch.Size([2048, 1280, 1, 1, 1])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch1_norm.weight \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch1_norm.bias \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch1_norm.running_mean \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch1_norm.running_var \t torch.Size([2048])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch1_norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.conv_a.weight \t torch.Size([512, 1280, 3, 1, 1])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_a.weight \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_a.bias \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_a.running_mean \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_a.running_var \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.conv_b.weight \t torch.Size([512, 512, 1, 3, 3])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_b.weight \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_b.bias \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_b.running_mean \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_b.running_var \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.conv_c.weight \t torch.Size([2048, 512, 1, 1, 1])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_c.weight \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_c.bias \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_c.running_mean \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_c.running_var \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.0.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.conv_a.weight \t torch.Size([512, 2048, 3, 1, 1])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_a.weight \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_a.bias \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_a.running_mean \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_a.running_var \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.conv_b.weight \t torch.Size([512, 512, 1, 3, 3])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_b.weight \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_b.bias \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_b.running_mean \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_b.running_var \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.conv_c.weight \t torch.Size([2048, 512, 1, 1, 1])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_c.weight \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_c.bias \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_c.running_mean \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_c.running_var \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.1.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.conv_a.weight \t torch.Size([512, 2048, 3, 1, 1])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_a.weight \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_a.bias \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_a.running_mean \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_a.running_var \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.conv_b.weight \t torch.Size([512, 512, 1, 3, 3])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_b.weight \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_b.bias \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_b.running_mean \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_b.running_var \t torch.Size([512])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.conv_c.weight \t torch.Size([2048, 512, 1, 1, 1])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_c.weight \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_c.bias \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_c.running_mean \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_c.running_var \t torch.Size([2048])\n",
      "blocks.4.multipathway_blocks.0.res_blocks.2.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch1_conv.weight \t torch.Size([256, 128, 1, 1, 1])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch1_norm.weight \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch1_norm.bias \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch1_norm.running_mean \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch1_norm.running_var \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch1_norm.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.conv_a.weight \t torch.Size([64, 128, 3, 1, 1])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_a.weight \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_a.bias \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_a.running_mean \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_a.running_var \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.conv_b.weight \t torch.Size([64, 64, 1, 3, 3])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_b.weight \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_b.bias \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_b.running_mean \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_b.running_var \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.conv_c.weight \t torch.Size([256, 64, 1, 1, 1])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_c.weight \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_c.bias \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_c.running_mean \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_c.running_var \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.0.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.conv_a.weight \t torch.Size([64, 256, 3, 1, 1])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_a.weight \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_a.bias \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_a.running_mean \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_a.running_var \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.conv_b.weight \t torch.Size([64, 64, 1, 3, 3])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_b.weight \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_b.bias \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_b.running_mean \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_b.running_var \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.conv_c.weight \t torch.Size([256, 64, 1, 1, 1])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_c.weight \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_c.bias \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_c.running_mean \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_c.running_var \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.1.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.conv_a.weight \t torch.Size([64, 256, 3, 1, 1])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_a.weight \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_a.bias \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_a.running_mean \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_a.running_var \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_a.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.conv_b.weight \t torch.Size([64, 64, 1, 3, 3])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_b.weight \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_b.bias \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_b.running_mean \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_b.running_var \t torch.Size([64])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_b.num_batches_tracked \t torch.Size([])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.conv_c.weight \t torch.Size([256, 64, 1, 1, 1])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_c.weight \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_c.bias \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_c.running_mean \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_c.running_var \t torch.Size([256])\n",
      "blocks.4.multipathway_blocks.1.res_blocks.2.branch2.norm_c.num_batches_tracked \t torch.Size([])\n",
      "blocks.6.proj.weight \t torch.Size([2, 2304])\n",
      "blocks.6.proj.bias \t torch.Size([2])\n",
      "\n",
      "Optimizer's state_dict:\n",
      "state \t {330: {'momentum_buffer': tensor([[-0.0144, -0.0040,  0.0082,  ...,  0.0262, -0.0293,  0.0527],\n",
      "        [ 0.0144,  0.0040, -0.0082,  ..., -0.0262,  0.0293, -0.0527]])}, 331: {'momentum_buffer': tensor([-0.0190,  0.0190])}}\n",
      "param_groups \t [{'lr': 0.0009990133642141358, 'momentum': 0.9, 'dampening': 0, 'weight_decay': 0, 'nesterov': False, 'maximize': False, 'initial_lr': 0.001, 'params': [0, 1, 2, 3, 4, 5, 6, 7, 8, 9, 10, 11, 12, 13, 14, 15, 16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29, 30, 31, 32, 33, 34, 35, 36, 37, 38, 39, 40, 41, 42, 43, 44, 45, 46, 47, 48, 49, 50, 51, 52, 53, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63, 64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 74, 75, 76, 77, 78, 79, 80, 81, 82, 83, 84, 85, 86, 87, 88, 89, 90, 91, 92, 93, 94, 95, 96, 97, 98, 99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112, 113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126, 127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140, 141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154, 155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168, 169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182, 183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196, 197, 198, 199, 200, 201, 202, 203, 204, 205, 206, 207, 208, 209, 210, 211, 212, 213, 214, 215, 216, 217, 218, 219, 220, 221, 222, 223, 224, 225, 226, 227, 228, 229, 230, 231, 232, 233, 234, 235, 236, 237, 238, 239, 240, 241, 242, 243, 244, 245, 246, 247, 248, 249, 250, 251, 252, 253, 254, 255, 256, 257, 258, 259, 260, 261, 262, 263, 264, 265, 266, 267, 268, 269, 270, 271, 272, 273, 274, 275, 276, 277, 278, 279, 280, 281, 282, 283, 284, 285, 286, 287, 288, 289, 290, 291, 292, 293, 294, 295, 296, 297, 298, 299, 300, 301, 302, 303, 304, 305, 306, 307, 308, 309, 310, 311, 312, 313, 314, 315, 316, 317, 318, 319, 320, 321, 322, 323, 324, 325, 326, 327, 328, 329, 330, 331]}]\n"
     ]
    }
   ],
   "source": [
    "# 모델의 state_dict 출력\n",
    "print(\"Model's state_dict:\")\n",
    "for param_tensor in model.state_dict():\n",
    "    print(param_tensor, \"\\t\", model.state_dict()[param_tensor].size())\n",
    "\n",
    "print()\n",
    "\n",
    "# 옵티마이저의 state_dict 출력\n",
    "print(\"Optimizer's state_dict:\")\n",
    "for var_name in optimizer.state_dict():\n",
    "    print(var_name, \"\\t\", optimizer.state_dict()[var_name])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 위치 설정할 것\n",
    "torch.save(model.state_dict(),'model_prac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 위치 설정할 것\n",
    "torch.save(model,'wholemodel_prac')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### load model test\n",
    "\n",
    "학습된 모델이 잘 작동하는지 확인한다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#파일 위치 설정할 것\n",
    "loadmodel = torch.load('wholemodel_prac')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = CustomDataset(metadata=metadata,transform=transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "prediction : Basketball label : Basketball , 1 th prediction is correct\n",
      "prediction : Basketball label : Basketball , 11 th prediction is correct\n",
      "prediction : Basketball label : Basketball , 21 th prediction is correct\n",
      "prediction : Basketball label : Basketball , 31 th prediction is correct\n",
      "prediction : Basketball label : Basketball , 41 th prediction is correct\n",
      "prediction : Basketball label : Basketball , 51 th prediction is correct\n",
      "prediction : Basketball label : Basketball , 61 th prediction is correct\n",
      "prediction : Basketball label : Basketball , 71 th prediction is correct\n",
      "prediction : Basketball label : Basketball , 81 th prediction is correct\n",
      "prediction : Basketball label : Basketball , 91 th prediction is correct\n",
      "prediction : Boxing label : Boxing , 101 th prediction is correct\n",
      "prediction : Boxing label : Boxing , 111 th prediction is correct\n",
      "prediction : Boxing label : Boxing , 121 th prediction is correct\n",
      "prediction : Boxing label : Boxing , 131 th prediction is correct\n",
      "prediction : Boxing label : Boxing , 141 th prediction is correct\n",
      "prediction : Boxing label : Boxing , 151 th prediction is correct\n",
      "prediction : Boxing label : Boxing , 161 th prediction is correct\n",
      "prediction : Boxing label : Boxing , 171 th prediction is correct\n",
      "prediction : Boxing label : Boxing , 181 th prediction is correct\n",
      "prediction : Boxing label : Boxing , 191 th prediction is correct\n"
     ]
    }
   ],
   "source": [
    "for i in range(1,200,10):\n",
    "    video,label = dataset[i]\n",
    "    \n",
    "    prediction = loadmodel(video)\n",
    "    post_act = torch.nn.Softmax(dim=1)\n",
    "    prediction = torch.argmax(post_act(prediction))\n",
    "    \n",
    "    if prediction == 1:\n",
    "        pred_label_name = 'Basketball'\n",
    "    else:\n",
    "        pred_label_name = 'Boxing'\n",
    "    \n",
    "    if label == 1:\n",
    "        label_name = 'Basketball'\n",
    "    else:\n",
    "        label_name = 'Boxing'\n",
    "    \n",
    "    if prediction == label:\n",
    "        print('prediction :',pred_label_name,'label :',label_name,',',i,'th prediction is correct')\n",
    "    else:\n",
    "        print('prediction :',pred_label_name,'label :',label_name,',',i,'th prediction is wrong')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "hide_input": false,
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
